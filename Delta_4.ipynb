{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "id": "2FPyz43JiOm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "QFJ_QXDvGEjN"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "\n",
        "API_KEY = userdata.get('API_KEY2')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "# Replace with your actual Gemini API key.\n",
        "genai.configure(api_key=API_KEY)\n",
        "image_path = \"/content/53e2c7ad-b789-4ab9-be1e-466a8cdaa1a0 (1).jpg\"  # Path to your image\n",
        "\n",
        "# --- Step 1: Load the image using OpenCV ---\n",
        "# Note: OpenCV loads images in BGR format.\n",
        "original_image = cv2.imread(image_path)\n",
        "if original_image is None:\n",
        "    raise FileNotFoundError(f\"Image file not found at path: {image_path}\")\n",
        "\n",
        "# --- Step 2: Convert to Grayscale ---\n",
        "gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# --- Step 3: Binarization using Adaptive Thresholding ---\n",
        "# This step converts the image to pure black and white.\n",
        "binarized = cv2.adaptiveThreshold(\n",
        "    gray,\n",
        "    maxValue=255,\n",
        "    adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "    thresholdType=cv2.THRESH_BINARY,\n",
        "    blockSize=11,\n",
        "    C=2\n",
        ")\n",
        "\n",
        "# --- Step 4: Noise Removal using Median Blur ---\n",
        "# Blurring helps remove small artifacts.\n",
        "denoised = cv2.medianBlur(binarized, ksize=3)\n",
        "\n",
        "# --- Step 5: Skew Correction ---\n",
        "# Find coordinates of non-zero pixels and compute the minimum area rectangle.\n",
        "coords = np.column_stack(np.where(denoised > 0))\n",
        "angle = cv2.minAreaRect(coords)[-1]\n",
        "# Adjust the angle as needed.\n",
        "if angle < -45:\n",
        "    angle = -(90 + angle)\n",
        "else:\n",
        "    angle = -angle\n",
        "\n",
        "# Get image center and compute rotation matrix.\n",
        "(h, w) = denoised.shape[:2]\n",
        "center = (w // 2, h // 2)\n",
        "M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "rotated = cv2.warpAffine(denoised, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "# --- Step 6: Contrast Enhancement using Histogram Equalization ---\n",
        "enhanced = cv2.equalizeHist(rotated)\n",
        "\n",
        "# --- Step 7: Morphological Operations (Dilation/Erosion) ---\n",
        "# Define a small kernel for morphological transformation.\n",
        "kernel = np.ones((1, 1), np.uint8)\n",
        "processed = cv2.morphologyEx(enhanced, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "# --- Optional: Save or display the preprocessed image for debugging ---\n",
        "# Uncomment the lines below to visualize the result using OpenCV.\n",
        "# cv2.imshow(\"Processed Image\", processed)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()\n",
        "\n",
        "# --- Step 8: Convert the preprocessed image to a format for Gemini API ---\n",
        "# Convert the OpenCV image (numpy array) to a PIL Image.\n",
        "processed_pil = Image.fromarray(processed)\n",
        "\n",
        "# Save the PIL image to a bytes buffer.\n",
        "buffered = io.BytesIO()\n",
        "# Use JPEG format; you can adjust this as needed.\n",
        "processed_pil.save(buffered, format=\"JPEG\")\n",
        "img_bytes = buffered.getvalue()\n",
        "\n",
        "new_prompt = (\n",
        "    \"You are an advanced text extraction and summarization engine with a strategic mindset. \"\n",
        "    \"I will provide you with an image containing a news article. Your task is to first extract all the text from the image exactly as it appears, preserving line breaks, punctuation, and spacing. Then create a concise and precise summary that captures the core information of the news. Next, compose an intense and motivational military dialogue that amplifies the summary and inspires determination, valor and strategic resolve in a manner akin to an elite military briefing. \"\n",
        "    \"The final output must be a single coherent paragraph that seamlessly integrates the summarized news with the motivational military dialogue. Do not include the full extracted text and do not add any extra formatting characters such as numbers or asterisks; only use regular characters, punctuation and spaces.\"\n",
        ")\n",
        "\n",
        "\n",
        "# --- Step 9: Prepare the Gemini API Request ---\n",
        "contents = [\n",
        "    {\n",
        "        \"parts\": [\n",
        "            new_prompt,\n",
        "            {\"mime_type\": \"image/jpeg\", \"data\": img_bytes},\n",
        "        ]\n",
        "    },\n",
        "]\n",
        "\n",
        "# --- Step 10: Generate Content (Extract Text via OCR) ---\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content(contents)\n",
        "\n",
        "# --- Step 11: Handle the Response ---\n",
        "if response.prompt_feedback and response.prompt_feedback.block_reason:\n",
        "    print(f\"Error: Prompt was blocked due to: {response.prompt_feedback.block_reason}\")\n",
        "    print(f\"Safety ratings: {response.prompt_feedback.safety_ratings}\")\n",
        "else:\n",
        "    print(\"Extracted Text (OCR):\\n\")\n",
        "    print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "fChp0nawQK6b",
        "outputId": "918946b4-9db4-40b9-9ddc-169bc5ac7d51"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text (OCR):\n",
            "\n",
            "The Indian government extended two crop insurance schemes until FY26, increasing their allocation to ₹69,515 crore.  An additional ₹3,850 crore subsidy for DAP fertilizer was approved to maintain retail prices.  Prime Minister Modi emphasized these decisions' dedication to enhancing farmers' prosperity.  Soldiers, the fate of our farmers rests on our shoulders! This is not a drill; this is a fight for the economic well-being of our nation. We will secure the supply chain and ensure affordable fertilizer for every farmer. We will adapt to global market volatility, we will overcome logistical challenges, and we will deliver!  Our resolve will ensure the prosperity of our farmers, bolstering our nation's strength and securing our future. Our mission is clear, our commitment unwavering. Execute the plan flawlessly!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# Set AWS credentials\n",
        "aws_access_key = userdata.get('aws1')\n",
        "aws_secret_key = userdata.get('aws2')\n",
        "aws_region = \"us-east-1\"  # Change region if needed\n",
        "\n",
        "# Initialize Polly client\n",
        "polly = boto3.client(\n",
        "    \"polly\",\n",
        "    aws_access_key_id=aws_access_key,\n",
        "    aws_secret_access_key=aws_secret_key,\n",
        "    region_name=aws_region\n",
        ")\n",
        "\n",
        "# Plain text example (Neural TTS)\n",
        "response = polly.synthesize_speech(\n",
        "    Engine=\"neural\",              # 'neural' or 'standard' are valid\n",
        "    LanguageCode=\"en-US\",         # optional but good to specify\n",
        "    VoiceId=\"Gregory\",            # or any other supported neural voice\n",
        "    OutputFormat=\"mp3\",\n",
        "    Text= response.text\n",
        ")\n",
        "\n",
        "# Save the audio file\n",
        "with open(\"RAH.mp3\", \"wb\") as file:\n",
        "    file.write(response[\"AudioStream\"].read())\n",
        "\n",
        "print(\"Audio saved as Gregory.mp3\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G56Yt-ZDdWIn",
        "outputId": "cbe8dc1d-e93e-43b4-b4ff-8e384e4a9457"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio saved as Gregory.mp3\n"
          ]
        }
      ]
    }
  ]
}